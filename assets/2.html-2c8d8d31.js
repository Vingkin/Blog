const e=JSON.parse('{"key":"v-6142c900","path":"/bigdata/hadoop/mapreduce/2.html","title":"MapReduce 基础编程","lang":"zh-CN","frontmatter":{"title":"MapReduce 基础编程","description":"1. MapReduce Partition分区 注意分区与分组的区别，分区的目的是通过设置ReduceTask的数量将数据输出到不同的文件中。而每一个分组调用一次reduce程序。 输出文件的个数与ReduceTask个数是一种对等关系，有几个ReduceTask，最终程序就输出几个文件。 对于MapTask究竟给哪个ReduceTask处理，这就是数据分区问题。 可以自己制定ReduceTask的个数： job.setNumReduceTasks(3);","head":[["meta",{"property":"og:url","content":"https://vingkin.github.io/Blog/Blog/bigdata/hadoop/mapreduce/2.html"}],["meta",{"property":"og:site_name","content":"Vingkin的学习博客"}],["meta",{"property":"og:title","content":"MapReduce 基础编程"}],["meta",{"property":"og:description","content":"1. MapReduce Partition分区 注意分区与分组的区别，分区的目的是通过设置ReduceTask的数量将数据输出到不同的文件中。而每一个分组调用一次reduce程序。 输出文件的个数与ReduceTask个数是一种对等关系，有几个ReduceTask，最终程序就输出几个文件。 对于MapTask究竟给哪个ReduceTask处理，这就是数据分区问题。 可以自己制定ReduceTask的个数： job.setNumReduceTasks(3);"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-09-25T11:35:18.000Z"}],["meta",{"property":"article:author","content":"Vingkin"}],["meta",{"property":"article:modified_time","content":"2023-09-25T11:35:18.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"MapReduce 基础编程\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2023-09-25T11:35:18.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Vingkin\\"}]}"]]},"headers":[{"level":2,"title":"1. MapReduce Partition分区","slug":"_1-mapreduce-partition分区","link":"#_1-mapreduce-partition分区","children":[]},{"level":2,"title":"2. MapReduce Combiner规约","slug":"_2-mapreduce-combiner规约","link":"#_2-mapreduce-combiner规约","children":[{"level":3,"title":"2.1 Combiner组件的使用","slug":"_2-1-combiner组件的使用","link":"#_2-1-combiner组件的使用","children":[]}]},{"level":2,"title":"3. COVID-19病例统计","slug":"_3-covid-19病例统计","link":"#_3-covid-19病例统计","children":[{"level":3,"title":"3.1 各州累计病例数量统计","slug":"_3-1-各州累计病例数量统计","link":"#_3-1-各州累计病例数量统计","children":[]},{"level":3,"title":"3.2 各州累计病例分区统计","slug":"_3-2-各州累计病例分区统计","link":"#_3-2-各州累计病例分区统计","children":[]},{"level":3,"title":"3.3 各州累计病例数最多top1县","slug":"_3-3-各州累计病例数最多top1县","link":"#_3-3-各州累计病例数最多top1县","children":[]}]},{"level":2,"title":"4. MapReduce并行度机制","slug":"_4-mapreduce并行度机制","link":"#_4-mapreduce并行度机制","children":[{"level":3,"title":"4.1 MapTask并行度机制","slug":"_4-1-maptask并行度机制","link":"#_4-1-maptask并行度机制","children":[]},{"level":3,"title":"4.2 ReduceTask并行度机制","slug":"_4-2-reducetask并行度机制","link":"#_4-2-reducetask并行度机制","children":[]}]},{"level":2,"title":"5. MapReduce工作流程详解","slug":"_5-mapreduce工作流程详解","link":"#_5-mapreduce工作流程详解","children":[{"level":3,"title":"5.1 MapTask工作机制详解","slug":"_5-1-maptask工作机制详解","link":"#_5-1-maptask工作机制详解","children":[]}]},{"level":2,"title":"5.2 ReduceTask工作机制详解","slug":"_5-2-reducetask工作机制详解","link":"#_5-2-reducetask工作机制详解","children":[]}],"git":{"createdTime":1695641718000,"updatedTime":1695641718000,"contributors":[{"name":"Vingkin","email":"1830053226@qq.com","commits":1}]},"readingTime":{"minutes":14.11,"words":4232},"filePathRelative":"bigdata/hadoop/mapreduce/2.md","localizedDate":"2023年9月25日","excerpt":"<h2> 1. MapReduce Partition分区</h2>\\n<blockquote>\\n<p>注意分区与分组的区别，分区的目的是通过设置ReduceTask的数量将数据输出到不同的文件中。而每一个分组调用一次reduce程序。</p>\\n</blockquote>\\n<p>输出文件的个数与ReduceTask个数是一种对等关系，有几个ReduceTask，最终程序就输出几个文件。</p>\\n<p>对于MapTask究竟给哪个ReduceTask处理，这就是<strong>数据分区</strong>问题。</p>\\n<p>可以自己制定ReduceTask的个数：</p>\\n<ul>\\n<li><code>job.setNumReduceTasks(3);</code></li>\\n</ul>","copyright":{"author":"Vingkin"},"autoDesc":true}');export{e as data};
